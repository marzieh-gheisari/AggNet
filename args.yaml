vlad_dim : 128
m_set : 4
model_type : "resnet50_128" #
dataroot : "/nfs/nas4/marzieh/marzieh/VGG_Face2/lfw/lfw-deepfunneled/"
lr : 0.001 # 0.001 learning rate of 0.001 for pre-training and 0.0001 for fine-tuning
n_epoch : 200
run_name : 'Run01'
exp_name : 'vgg2'
num_workers : 0
n_save_epoch : 1
n_classes : 32
n_samples : 2
n_batches_train : 0  # None
n_batches_valid : 0  # None
upper_vgg : 0
num_clusters : 8
clustering : 0
vlad_v2 : 0
loss : 'loss_bc'
optimizer : 'sgd'
alpha : 0.001  # 0.01, 0.001
